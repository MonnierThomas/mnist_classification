{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST pipeline classification and image prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to requirements.txt, you already installed the libraries needed\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from mnist import MNIST\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and load the training sets of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have followed the instructions correctly, you normally have\n",
    "# a folder \"train\" containing the training images and labels\n",
    "# You need to open the files thanks to the MNIST method and then load them \n",
    "# with proper meaning with load_training()\n",
    "\n",
    "mndata = MNIST(r'train')\n",
    "X_train, Y_train = mndata.load_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and load the test sets of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You must also have a folder \"test\" containing the test imanges and labels\n",
    "# You need to open the files thanks to the MNIST method and then load them \n",
    "# with proper meaning with load_testing()\n",
    "\n",
    "mndata = MNIST(r'test')\n",
    "X_test, Y_test = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of pixels of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "def number_of_pixels(train : list, test : list) -> int:\n",
    "    \"\"\"\n",
    "    This function calls the training images and test images and returns the square root of the number of pixels of each image.\n",
    "    The postulate is that every images of the training set and the test set have the same number of pixels.\n",
    "    It if is not the case between the training and testing sets, then an error is printed to warn the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if len(train[1]) == len(test[1]):\n",
    "            nb_pixels = len(train[1])\n",
    "            return sqrt(nb_pixels)\n",
    "    except:\n",
    "        print(\"The numbers of pixels of images in the train dataset and the test dataset are not the same, thus it is abnormal\")\n",
    "\n",
    "nb_pixels = number_of_pixels(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpys for train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_numpy(Y_train : list, Y_test : list):\n",
    "    \"\"\"\n",
    "    This function calls the training labels and test labels and converts those lists into arrays.\n",
    "    This function returns the arrays corresponding to those lists.\n",
    "    \"\"\"\n",
    "    return np.array(Y_train), np.array(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline classification method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966\n"
     ]
    }
   ],
   "source": [
    "def pipeline_classification():\n",
    "    \"\"\"\n",
    "    This function executes the pipeline method of scikit-sklearn.\n",
    "    See more information on https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "    \"\"\"\n",
    "    nb_pixels = number_of_pixels(X_train, X_test)\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())]) # initialisation of the method\n",
    "    Y_train_r, Y_test_r = ger_numpy(Y_train, Y_test)\n",
    "    pipe.fit(X_train, Y_train_r)                                    # fitting the pipline to the training images and labels\n",
    "    return pipe.score(X_Test, Y_test)                               # score obtained by applying the pipeline to the test images and labels\n",
    "\n",
    "pipeline_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download an image and get the result of its classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fit(data):\n",
    "    \"\"\"\n",
    "    This function calls an array of an image and converts it to a list fitting the MNIST model.\n",
    "    If the array contains 4 values (RGB + Greyscale) for each pixel, the function returns only the list of the Greyscale part of the image.\n",
    "    Else, it returns the list of the average of the three values (RGB) for each pixel.\n",
    "    \"\"\"\n",
    "    if len(data[0][0]) == 4:\n",
    "        return [data[i][j][3] for j in range(nb_pixels) for i in range(nb_pixels)]\n",
    "    else:\n",
    "        data_final = []\n",
    "        for i in range(nb_pixels):\n",
    "            for j in range(nb_pixels):\n",
    "                x = 0\n",
    "                for k in range(len(data[0][0]):\n",
    "                    x += data[i][j][k]\n",
    "                    data_final.append(x/3)\n",
    "        return data_final\n",
    "                \n",
    "def invert_image(data):\n",
    "    \"\"\"\n",
    "    This function calls an array of an image and returns the the inverted values of pixels.\n",
    "    For instance, 0 -> 255 and 185 -> 70\n",
    "    \"\"\"\n",
    "    data_reverse = []\n",
    "    for x in image:\n",
    "        image_reverse.append(abs(x - 255))\n",
    "    return data_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(path):\n",
    "    \"\"\"\n",
    "    This function calls the path of an image, open it thanks to the library PIL and the method Image.\n",
    "    Then the function converts the image to a numpy array.\n",
    "    Finally the function predicts the classification of the image thanks to the pipeline method\n",
    "    \"\"\"\n",
    "    image = Image.open(path).resize((nb_pixels, nb_pixels)) # resize the image in order to fit the MNIST sets\n",
    "    data = numpy.asarray(image)                             # convert the image to an array containing the pixels of the image\n",
    "    data_fixed = data_fit(data)                             \n",
    "    data_final = inver_image(data_fixed)                    # images are very often inverted in terms of values in comparison to MNIST images so don't forget to check\n",
    "    return pipe.predict(np.array(data_final).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"image\": \"8.jpg\",\n",
      "   \"prediction\": 8,\n",
      "   \"accuracy\": 0.966\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def res_to_json(path):\n",
    "    \"\"\"\n",
    "    This function calls the path of an image and returns the prediction of its classification in a JSON file containing\n",
    "    its path, its classification and the accuracy of the method used.\n",
    "    \"\"\"\n",
    "    accuracy = pipeline_classification()\n",
    "    res = get_classification(path)[0]\n",
    "    \n",
    "    json_d = {\n",
    "        \"image\": f'{path}',\n",
    "        \"prediction\": f'{res}',\n",
    "        \"accuracy\": f'{accuracy}'\n",
    "    }\n",
    "    return json.dumps(dictionnary, indent = 3, sort_keys = True)\n",
    "\n",
    "res_to_json(r\"8.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
