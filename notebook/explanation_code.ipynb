{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST pipeline classification and image prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to requirements.txt, you already installed the libraries needed but you need to import the methods\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Open and load the training sets of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have followed the instructions correctly, you normally have\n",
    "# a folder \"train\" containing the training images and labels\n",
    "# You need to open the files thanks to the MNIST method and then load them \n",
    "# with proper meaning with load_training()\n",
    "\n",
    "mndata = MNIST(r'train')\n",
    "X_train, Y_train = mndata.load_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Open and load the test sets of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You must also have a folder \"test\" containing the test imanges and labels\n",
    "# You need to open the files thanks to the MNIST method and then load them \n",
    "# with proper meaning with load_testing()\n",
    "\n",
    "mndata = MNIST(r'test')\n",
    "X_test, Y_test = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading both training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace 3D matrix by list of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of list of training images instead of a 3D matrix\n",
    "train_images = []\n",
    "for image in X_train:\n",
    "    train_images.append(image.reshape((1, 28*28))[0])\n",
    "\n",
    "# Create a list of list of test images instead of a 3D matrix\n",
    "test_images = []\n",
    "for image in X_test:\n",
    "    test_images.append(image.reshape((1, 28*28))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of pixels of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "def number_of_pixels(train : list, test : list) -> int:\n",
    "    \"\"\"\n",
    "    This function calls the training images and test images and returns the square root of the number of pixels of each image.\n",
    "    The postulate is that every images of the training set and the test set have the same number of pixels.\n",
    "    It if is not the case between the training and testing sets, then an error is printed to warn the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if len(train[1]) == len(test[1]):\n",
    "            nb_pixels = len(train[1])\n",
    "            return int(sqrt(nb_pixels))\n",
    "    except:\n",
    "        print(\"The numbers of pixels of images in the train dataset and the test dataset are not the same, thus it is abnormal\")\n",
    "        \n",
    "nb_pixels = number_of_pixels(train_images, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpys for train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_numpy(Y_train : list, Y_test : list):\n",
    "    \"\"\"\n",
    "    This function calls the training labels and test labels and converts those lists into arrays.\n",
    "    This function returns the arrays corresponding to those lists.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array(Y_train), np.array(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline classification method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966\n"
     ]
    }
   ],
   "source": [
    "def pipeline_classification():\n",
    "    \"\"\"\n",
    "    This function executes the pipeline method of scikit-sklearn.\n",
    "    See more information on https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_pixels = number_of_pixels(train_images, test_images)\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())]) # initialisation of the method\n",
    "    train_labels, test_labels = get_numpy(Y_train, Y_test)\n",
    "    pipe.fit(train_images, train_labels)                            # fitting the pipline to the training images and labels\n",
    "    \n",
    "    return pipe, pipe.score(test_images, test_labels)               # score obtained by applying the pipeline to the test images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download an image and get the result of its classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fit(data):\n",
    "    \"\"\"\n",
    "    This function calls an array of an image and converts it to a list fitting the MNIST model.\n",
    "    If the array contains 4 values (RGB + Greyscale) for each pixel, the function returns only the list of the Greyscale part of the image.\n",
    "    Else, it returns the list of the average of the three values (RGB) for each pixel.\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_pixels = number_of_pixels(train_images, test_images)\n",
    "    if len(data[0][0]) == 4:\n",
    "        return [data[i][j][3] for j in range(nb_pixels) for i in range(nb_pixels)]\n",
    "    else:\n",
    "        data_final = []\n",
    "        for i in range(nb_pixels):\n",
    "            for j in range(nb_pixels):\n",
    "                x = 0\n",
    "                for k in range(3):\n",
    "                    x += data[i][j][k]\n",
    "                data_final.append(x/3)\n",
    "        return data_final\n",
    "                \n",
    "def invert_image(data):\n",
    "    \"\"\"\n",
    "    This function calls an array of an image and returns the the inverted values of pixels.\n",
    "    For instance, 0 -> 255 and 185 -> 70\n",
    "    \"\"\"\n",
    "    \n",
    "    data_reverse = []\n",
    "    for x in data:\n",
    "        data_reverse.append(abs(x - 255))\n",
    "    return data_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(path, pipe):\n",
    "    \"\"\"\n",
    "    This function calls the path of an image, open it thanks to the library PIL and the method Image.\n",
    "    Then the function converts the image to a numpy array.\n",
    "    Finally the function predicts the classification of the image thanks to the pipeline method\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_pixels = number_of_pixels(train_images, test_images)\n",
    "    image = Image.open(path).resize((nb_pixels, nb_pixels)) # resize the image in order to fit the MNIST sets\n",
    "    data = np.asarray(image)                                # convert the image to an array containing the pixels of the image\n",
    "    data_fixed = data_fit(data)\n",
    "    data_final = invert_image(data_fixed)                   # images are very often inverted in terms of values in comparison to MNIST images so don't forget to check\n",
    "    return pipe.predict(np.array(data_final).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"image\": \"8.jpg\",\n",
      "   \"prediction\": 8,\n",
      "   \"accuracy\": 0.966\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def res_to_json(path):\n",
    "    \"\"\"\n",
    "    This function calls the path of an image and returns the prediction of its classification in a JSON file containing\n",
    "    its path, its classification and the accuracy of the method used.\n",
    "    \"\"\"\n",
    "    \n",
    "    pipe, accuracy = pipeline_classification()\n",
    "    res = get_classification(path, pipe)[0]\n",
    "    \n",
    "    json_d = {\n",
    "        \"image\": f'{path}',\n",
    "        \"prediction\": f'{res}',\n",
    "        \"accuracy\": f'{accuracy}'\n",
    "    }\n",
    "    return json.dumps(json_d, indent = 3, sort_keys = True)\n",
    "\n",
    "res_to_json(r\"8.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
